# Intelligent Query Retrieval System - Backend

This is the backend API for the Intelligent Query Retrieval System, built with FastAPI, PostgreSQL, and Pinecone vector database.

## ğŸ—ï¸ Architecture

### Core Components
- **FastAPI**: Modern, fast web framework for building APIs
- **PostgreSQL**: Primary database for documents and metadata
- **Pinecone**: Vector database for semantic search
- **OpenRouter/DeepSeek**: LLM integration for intelligent responses
- **SQLAlchemy**: Async ORM for database operations

### Key Features
- ğŸ“„ **Document Processing**: Upload and process PDF, DOCX, DOC, EML files
- ğŸ” **Hybrid Search**: Vector embeddings + text-based fallback
- ğŸŒ **Web Search Fallback**: Online search when documents don't contain answers
- ğŸ›¡ï¸ **Duplicate Detection**: Hash-based duplicate prevention
- ğŸ“Š **Query History**: Track and store all queries and responses

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- PostgreSQL database
- Pinecone account (optional, has fallback)
- OpenRouter API key

### Installation

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure environment:**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and database settings
   ```

3. **Run the server:**
   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py    # Document upload/management
â”‚   â”‚   â”‚   â””â”€â”€ queries.py      # Query processing
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ database.py         # Database configuration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ document.py         # SQLAlchemy models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ document_processor.py  # File processing
â”‚   â”‚   â”œâ”€â”€ vector_store.py        # Pinecone integration
â”‚   â”‚   â”œâ”€â”€ search_engine.py       # Hybrid search
â”‚   â”‚   â”œâ”€â”€ query_processor.py     # Query orchestration
â”‚   â”‚   â””â”€â”€ llm_engine.py          # LLM integration
â”‚   â”œâ”€â”€ config.py               # Configuration settings
â”‚   â””â”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ tests/                      # Test files
â”œâ”€â”€ uploads/                    # Uploaded files storage
â”œâ”€â”€ scripts/                    # Setup scripts
â””â”€â”€ requirements.txt            # Python dependencies
```

## ğŸ”§ Configuration

Key environment variables in `.env`:

```bash
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/db_name

# OpenRouter/DeepSeek (Required)
OPENAI_API_KEY=your_openrouter_api_key
OPENAI_MODEL=deepseek/deepseek-r1-0528:free
OPENAI_BASE_URL=https://openrouter.ai/api/v1

# Pinecone (Optional)
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=us-east1-gcp
PINECONE_INDEX_NAME=document-retrieval

# Features
ENABLE_EMBEDDINGS=true
```

## ğŸ“š API Endpoints

### Document Management
- `POST /api/v1/documents/upload` - Upload and process documents
- `GET /api/v1/documents` - List documents with pagination
- `GET /api/v1/documents/{id}` - Get document details
- `DELETE /api/v1/documents/{id}` - Delete document

### Query Processing
- `POST /api/v1/query` - Process natural language queries
- `GET /api/v1/queries/history` - Get query history
- `GET /api/v1/queries/{id}` - Get specific query details

## ğŸ§ª Testing

Run the test suite:
```bash
# Basic functionality test
python test_simple_query.py

# Document upload test
python test_document_search.py

# API tests
python -m pytest tests/
```

## ğŸ³ Docker Support

Build and run with Docker:
```bash
docker-compose up --build
```

## ğŸ” How It Works

1. **Document Upload**: Files are processed, chunked, and stored
2. **Embedding Generation**: Text chunks are converted to vector embeddings
3. **Vector Storage**: Embeddings stored in Pinecone for semantic search
4. **Query Processing**: 
   - Search documents using vector similarity
   - Fall back to text-based search if needed
   - Use web search if no relevant documents found
5. **LLM Response**: Generate intelligent answers using retrieved context

## ğŸ› ï¸ Development

### Adding New Features
- **Document Types**: Extend `document_processor.py`
- **Search Methods**: Modify `search_engine.py`
- **LLM Models**: Update `llm_engine.py`
- **API Endpoints**: Add routes in `api/routes/`

### Database Migrations
The system uses SQLAlchemy with automatic table creation. For production, implement proper migrations.

## ğŸ“Š Monitoring

The system includes structured logging with:
- Query processing times
- Search result counts
- Error tracking
- Performance metrics

## ğŸ”’ Security

- Input validation with Pydantic
- SQL injection prevention with SQLAlchemy
- File type restrictions for uploads
- Environment-based configuration
